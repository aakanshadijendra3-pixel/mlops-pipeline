{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2134f63a",
      "metadata": {
        "id": "2134f63a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a467445",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a467445",
        "outputId": "0902eabf-0f16-4101-bfa3-9c46eeaed539"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([900, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Step 1: Create an imbalanced binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "np.unique(y, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7fc473ad",
      "metadata": {
        "id": "7fc473ad"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce174acd",
      "metadata": {
        "id": "ce174acd"
      },
      "source": [
        "#### Handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0c6d768a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c6d768a",
        "outputId": "07ddcf73-b0ce-498a-850c-06f2fa0e5e99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([619, 619]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "smt = SMOTETomek(random_state=42)\n",
        "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "np.unique(y_train_res, return_counts=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f04a52b2",
      "metadata": {
        "id": "f04a52b2"
      },
      "source": [
        "### Track Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "82fdaf1c",
      "metadata": {
        "id": "82fdaf1c"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    (\n",
        "        \"Logistic Regression\",\n",
        "        {\"C\": 1, \"solver\": 'liblinear'},\n",
        "        LogisticRegression(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"Random Forest\",\n",
        "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
        "        RandomForestClassifier(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"XGBClassifier\",\n",
        "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
        "        XGBClassifier(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"XGBClassifier With SMOTE\",\n",
        "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
        "        XGBClassifier(),\n",
        "        (X_train_res, y_train_res),\n",
        "        (X_test, y_test)\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "13a992c3",
      "metadata": {
        "id": "13a992c3"
      },
      "outputs": [],
      "source": [
        "reports = []\n",
        "\n",
        "for model_name, params, model, train_set, test_set in models:\n",
        "    X_train = train_set[0]\n",
        "    y_train = train_set[1]\n",
        "    X_test = test_set[0]\n",
        "    y_test = test_set[1]\n",
        "\n",
        "    model.set_params(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    reports.append(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qa06XwRoRGmK"
      },
      "id": "Qa06XwRoRGmK",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d9301bc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9301bc0",
        "outputId": "0ef02167-41d3-4bcb-919e-6fd1875283ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.3.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==3.3.2 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.3.2-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.3.2 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.5)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.43)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.3.2->mlflow)\n",
            "  Downloading databricks_sdk-0.65.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.35.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow) (1.17.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow) (0.47.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow) (0.57b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (2025.8.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.3.2->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.3.2-py3-none-any.whl (26.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.3.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.3.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.65.0-py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.9/705.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: gunicorn, graphql-core, graphql-relay, docker, graphene, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed databricks-sdk-0.65.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.3.2 mlflow-skinny-3.3.2 mlflow-tracing-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9ad9cf4d",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ad9cf4d",
        "outputId": "0b29cac7-1274-418c-ba33-7b02e1f79243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/09/11 12:23:40 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection' does not exist. Creating a new experiment.\n",
            "2025/09/11 12:23:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 12:23:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "2025/09/11 12:23:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 12:23:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "2025/09/11 12:23:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 12:24:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "2025/09/11 12:24:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 12:24:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Initialize MLflow\n",
        "mlflow.set_experiment(\"Anomaly Detection\")\n",
        "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "\n",
        "for i, element in enumerate(models):\n",
        "    model_name = element[0]\n",
        "    params = element[1]\n",
        "    model = element[2]\n",
        "    report = reports[i]\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name):\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metrics({\n",
        "            'accuracy': report['accuracy'],\n",
        "            'recall_class_1': report['1']['recall'],\n",
        "            'recall_class_0': report['0']['recall'],\n",
        "            'f1_score_macro': report['macro avg']['f1-score']\n",
        "        })\n",
        "\n",
        "        if \"XGB\" in model_name:\n",
        "            mlflow.xgboost.log_model(model, \"model\")\n",
        "        else:\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "        # if \"XGB\" in model_name:\n",
        "        #     model_uri = f\"runs:/{run_id}/model\"\n",
        "        #     mlflow.register_model(model_uri=model_uri, name=model_name)\n",
        "\n",
        "        #     print(f\"Model {model_name} registered with run_id: {run_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7446ae8a",
      "metadata": {
        "id": "7446ae8a"
      },
      "source": [
        "### Register the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_uri = f\"runs:/{run_id}/model\"\n",
        "# mlflow.register_model(model_uri=model_uri, name=model_name)\n",
        "# print(f\"Model {model_name} registered with run_id: {run_id}\")"
      ],
      "metadata": {
        "id": "LKoD4AUp1Wtm"
      },
      "id": "LKoD4AUp1Wtm",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_experiment(\"Anomaly Detection\")\n",
        "# Optional: set your tracking URI if remote\n",
        "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "\n",
        "for i, element in enumerate(models):\n",
        "    model_name = element[0]\n",
        "    params = element[1]\n",
        "    model = element[2]\n",
        "    report = reports[i]\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name) as run:\n",
        "        run_id = run.info.run_id\n",
        "\n",
        "        # Log parameters and metrics\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metrics({\n",
        "            'accuracy': report['accuracy'],\n",
        "            'recall_class_1': report['1']['recall'],\n",
        "            'recall_class_0': report['0']['recall'],\n",
        "            'f1_score_macro': report['macro avg']['f1-score']\n",
        "        })\n",
        "\n",
        "        # Log model\n",
        "        if \"XGB\" in model_name:\n",
        "            mlflow.xgboost.log_model(model, \"model\")\n",
        "        else:\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "        # ✅ Register the model (inside the active run)\n",
        "        model_uri = f\"runs:/{run_id}/model\"\n",
        "        mlflow.register_model(model_uri=model_uri, name=model_name)\n",
        "\n",
        "        print(f\"✅ Model {model_name} registered successfully with run_id: {run_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSrprKOJ4oo1",
        "outputId": "ed8e7e59-eeb2-4467-bd7f-e366d11a7ecd"
      },
      "id": "jSrprKOJ4oo1",
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/11 12:24:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 12:24:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Logistic Regression'.\n",
            "2025/09/11 12:24:13 WARNING mlflow.tracking._model_registry.fluent: Run with id 8d4f0b11b9fe4501ade58085b09edaf5 has no artifacts at artifact path 'model', registering model based on models:/m-8bec74fbddde4dec923f95ed66d54426 instead\n",
            "Created version '1' of model 'Logistic Regression'.\n",
            "2025/09/11 12:24:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model Logistic Regression registered successfully with run_id: 8d4f0b11b9fe4501ade58085b09edaf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 12:24:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Random Forest'.\n",
            "2025/09/11 12:24:21 WARNING mlflow.tracking._model_registry.fluent: Run with id 8323962e26da4cc28e915681393c88f4 has no artifacts at artifact path 'model', registering model based on models:/m-20ef85ee28f142f99c30089fee61c1ee instead\n",
            "Created version '1' of model 'Random Forest'.\n",
            "2025/09/11 12:24:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model Random Forest registered successfully with run_id: 8323962e26da4cc28e915681393c88f4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 12:24:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'XGBClassifier'.\n",
            "2025/09/11 12:24:29 WARNING mlflow.tracking._model_registry.fluent: Run with id 84db9e11f6a648cca868159657701708 has no artifacts at artifact path 'model', registering model based on models:/m-51cda47480824912bfc3325f608338a7 instead\n",
            "Created version '1' of model 'XGBClassifier'.\n",
            "2025/09/11 12:24:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model XGBClassifier registered successfully with run_id: 84db9e11f6a648cca868159657701708\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 12:24:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'XGBClassifier With SMOTE'.\n",
            "2025/09/11 12:24:35 WARNING mlflow.tracking._model_registry.fluent: Run with id 3208104cc28048faa12d7e6d3e82ce90 has no artifacts at artifact path 'model', registering model based on models:/m-5d3ce4fb8f994ba0a60e7e418a5f49aa instead\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model XGBClassifier With SMOTE registered successfully with run_id: 3208104cc28048faa12d7e6d3e82ce90\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created version '1' of model 'XGBClassifier With SMOTE'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.register_model(model_uri=f\"runs:/{run_id}/model\", name=\"XGB-Smote\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7pCKUhy5p2_",
        "outputId": "e2cc8a66-46b1-41e4-a368-c5673e726b52"
      },
      "id": "k7pCKUhy5p2_",
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'XGB-Smote'.\n",
            "2025/09/11 12:24:35 WARNING mlflow.tracking._model_registry.fluent: Run with id 3208104cc28048faa12d7e6d3e82ce90 has no artifacts at artifact path 'model', registering model based on models:/m-5d3ce4fb8f994ba0a60e7e418a5f49aa instead\n",
            "Created version '1' of model 'XGB-Smote'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1757593475243, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1757593475243, metrics=[<Metric: dataset_digest=None, dataset_name=None, key='accuracy', model_id='m-5d3ce4fb8f994ba0a60e7e418a5f49aa', run_id='3208104cc28048faa12d7e6d3e82ce90', step=0, timestamp=1757593470065, value=0.9633333333333334>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='f1_score_macro', model_id='m-5d3ce4fb8f994ba0a60e7e418a5f49aa', run_id='3208104cc28048faa12d7e6d3e82ce90', step=0, timestamp=1757593470065, value=0.8996319839411174>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='recall_class_0', model_id='m-5d3ce4fb8f994ba0a60e7e418a5f49aa', run_id='3208104cc28048faa12d7e6d3e82ce90', step=0, timestamp=1757593470065, value=0.9777777777777777>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='recall_class_1', model_id='m-5d3ce4fb8f994ba0a60e7e418a5f49aa', run_id='3208104cc28048faa12d7e6d3e82ce90', step=0, timestamp=1757593470065, value=0.8333333333333334>], model_id='m-5d3ce4fb8f994ba0a60e7e418a5f49aa', name='XGB-Smote', params={'eval_metric': 'logloss', 'use_label_encoder': 'False'}, run_id='3208104cc28048faa12d7e6d3e82ce90', run_link=None, source='models:/m-5d3ce4fb8f994ba0a60e7e418a5f49aa', status='READY', status_message=None, tags={}, user_id=None, version=1>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b074a08",
      "metadata": {
        "id": "1b074a08"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow.xgboost\n",
        "\n",
        "model_name = \"XGB-Smote\"\n",
        "model_version = 1\n",
        "model_uri = f\"models:/{model_name}/{model_version}\"\n",
        "\n",
        "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
        "\n",
        "# Predict\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(y_pred[:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS187ynQ7MAv",
        "outputId": "69c7e007-d61f-413b-83ed-398e9bd029ed"
      },
      "id": "zS187ynQ7MAv",
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a40fef12",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40fef12",
        "outputId": "f2e1fd64-d1dc-4cf2-c59c-f4654cc15664"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_version = 1\n",
        "model_uri = f\"models:/{model_name}/{model_version}\"\n",
        "\n",
        "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred[:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8d2893",
      "metadata": {
        "id": "5f8d2893"
      },
      "source": [
        "### Transition the Model to Production"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "model_name = \"XGB-Smote\"\n",
        "production_model_name = \"anomaly-detection-prod\"\n",
        "source_version = 1\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# (Optional) set alias for clarity\n",
        "client.set_registered_model_alias(model_name, \"challenger\", version=source_version)\n",
        "\n",
        "# Make sure destination exists\n",
        "try:\n",
        "    client.create_registered_model(production_model_name)\n",
        "except Exception:\n",
        "    pass  # Already exists\n",
        "\n",
        "# Copy the version\n",
        "client.copy_model_version(\n",
        "    src_model_uri=f\"models:/{model_name}@challenger\",\n",
        "    dst_name=production_model_name\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9sRU3rs8P87",
        "outputId": "2b657a69-afbd-4e3c-be9a-6ddac1c98a82"
      },
      "id": "B9sRU3rs8P87",
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'anomaly-detection-prod' already exists. Creating a new version of this model...\n",
            "Copied version '1' of model 'XGB-Smote' to version '1' of model 'anomaly-detection-prod'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1757593475335, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1757593475335, metrics=None, model_id=None, name='anomaly-detection-prod', params=None, run_id='3208104cc28048faa12d7e6d3e82ce90', run_link=None, source='models:/XGB-Smote/1', status='READY', status_message=None, tags={}, user_id=None, version=1>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "\n",
        "model_name = \"XGB-Smote\"                # Source model\n",
        "production_model_name = \"anomaly-detection-prod\"  # Destination registry\n",
        "source_version = 1\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# Set alias \"challenger\" on source model\n",
        "client.set_registered_model_alias(model_name, \"challenger\", version=source_version)\n",
        "\n",
        "# Make sure destination model registry exists\n",
        "try:\n",
        "    client.create_registered_model(production_model_name)\n",
        "except Exception:\n",
        "    pass  # Already exists\n",
        "\n",
        "# Copy challenger into production registry\n",
        "dst_model_version = client.copy_model_version(\n",
        "    src_model_uri=f\"models:/{model_name}@challenger\",\n",
        "    dst_name=production_model_name\n",
        ")\n",
        "\n",
        "# Set alias \"champion\" on the copied version\n",
        "client.set_registered_model_alias(\n",
        "    production_model_name,\n",
        "    \"champion\",\n",
        "    version=dst_model_version.version\n",
        ")\n",
        "\n",
        "#Load champion model & predict\n",
        "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
        "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(y_pred[:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvZwnGwljNWM",
        "outputId": "c05633f5-6413-4795-8b42-745c457f26a7"
      },
      "id": "EvZwnGwljNWM",
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'anomaly-detection-prod' already exists. Creating a new version of this model...\n",
            "Copied version '1' of model 'XGB-Smote' to version '2' of model 'anomaly-detection-prod'.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "# Download the model from MLflow Model Registry\n",
        "export_path = mlflow.artifacts.download_artifacts(\n",
        "    artifact_uri=\"models:/anomaly-detection-prod@champion\",\n",
        "    dst_path=\"exported_model\"\n",
        ")\n",
        "\n",
        "print(\"Model exported to:\", export_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a69f8588e1f84b6dad469ff277dd9397",
            "6c2bd15087594a72a655573174f211c6",
            "778058dda7d54d30be18f9257c7dfff6",
            "b74ebbe6b0d6427698c6606485147e05",
            "80aba6b93e5a44f6bc3e3bf9dba04c38",
            "0b168182731d4ffb9eb353ed38f888f5",
            "9c4884b00481468c92200bcae2fbb366",
            "2c264d1fd17747b2bfc044dee0e7c79e",
            "57d4ce004ae54ab5b47e901aac2f9b85",
            "9e9b13e039f14e3396900bc7c19ed4c6",
            "98fdd819eae54e199559ef067fc05697"
          ]
        },
        "id": "rsRXRf5suoSn",
        "outputId": "cbbe26da-d2d2-4f69-fa97-7ed692e24296"
      },
      "id": "rsRXRf5suoSn",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a69f8588e1f84b6dad469ff277dd9397"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model exported to: /content/exported_model/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Serving Script (FastAPI or Flask)"
      ],
      "metadata": {
        "id": "auiEVspIj1zt"
      },
      "id": "auiEVspIj1zt"
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import mlflow.pyfunc\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load exported model\n",
        "model = mlflow.pyfunc.load_model(\"exported_model\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"MLflow model is live inside Docker!\"}\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(data: dict):\n",
        "    X = [list(data.values())]\n",
        "    y_pred = model.predict(X)\n",
        "    return {\"prediction\": y_pred.tolist()}\n"
      ],
      "metadata": {
        "id": "3fF_hU8Yunbm"
      },
      "id": "3fF_hU8Yunbm",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile serve.py\n",
        "from fastapi import FastAPI\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "# Create FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load model from MLflow registry (champion alias)\n",
        "model_uri = \"models:/anomaly-detection-prod@champion\"\n",
        "model = mlflow.pyfunc.load_model(model_uri)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return {\"message\": \"MLflow model is live inside Docker!\"}\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(data: dict):\n",
        "    \"\"\"\n",
        "    Expects input like:\n",
        "    {\n",
        "        \"feature1\": 0.5,\n",
        "        \"feature2\": 1.2,\n",
        "        \"feature3\": -0.8\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Convert input dict → DataFrame\n",
        "    df = pd.DataFrame([data])\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(df)\n",
        "\n",
        "    return {\"prediction\": prediction.tolist()}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwBbLmeSj6JZ",
        "outputId": "9c4c3cce-12f4-479a-d5ee-aa3fe9480dc1"
      },
      "id": "xwBbLmeSj6JZ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing serve.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"serve.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2xJdnCwflZbk",
        "outputId": "41014dd4-161d-4e4d-b47f-9f24792a8f41"
      },
      "id": "2xJdnCwflZbk",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7858d79c-ea68-432b-aa71-62cf56c9a178\", \"serve.py\", 681)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Docker file"
      ],
      "metadata": {
        "id": "X35aoMDxl-Mq"
      },
      "id": "X35aoMDxl-Mq"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dockerfile\n",
        "# Base image with Python\n",
        "FROM python:3.9\n",
        "\n",
        "# Set working directory inside container\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy files\n",
        "COPY serve.py /app\n",
        "COPY requirements.txt /app\n",
        "\n",
        "# Install dependencies\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# Expose FastAPI port\n",
        "EXPOSE 8000\n",
        "\n",
        "# Start FastAPI app\n",
        "CMD [\"uvicorn\", \"serve:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPE2oag3ljRk",
        "outputId": "6f2bc128-2763-4667-e995-ad483b90130a"
      },
      "id": "cPE2oag3ljRk",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Dockerfile\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "phCZAO12mAGu",
        "outputId": "3a844130-c2eb-49fa-c84b-89b1e3f3dee5"
      },
      "id": "phCZAO12mAGu",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27e98348-eae4-4621-8cac-fac9103c723d\", \"Dockerfile\", 355)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RDpi2f7LQP0P"
      },
      "id": "RDpi2f7LQP0P"
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow\n",
        "fastapi\n",
        "uvicorn\n",
        "scikit-learn\n",
        "xgboost\n"
      ],
      "metadata": {
        "id": "QHHXWMWAmIE1"
      },
      "id": "QHHXWMWAmIE1",
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a69f8588e1f84b6dad469ff277dd9397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c2bd15087594a72a655573174f211c6",
              "IPY_MODEL_778058dda7d54d30be18f9257c7dfff6",
              "IPY_MODEL_b74ebbe6b0d6427698c6606485147e05"
            ],
            "layout": "IPY_MODEL_80aba6b93e5a44f6bc3e3bf9dba04c38"
          }
        },
        "6c2bd15087594a72a655573174f211c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b168182731d4ffb9eb353ed38f888f5",
            "placeholder": "​",
            "style": "IPY_MODEL_9c4884b00481468c92200bcae2fbb366",
            "value": "Downloading artifacts: 100%"
          }
        },
        "778058dda7d54d30be18f9257c7dfff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c264d1fd17747b2bfc044dee0e7c79e",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57d4ce004ae54ab5b47e901aac2f9b85",
            "value": 6
          }
        },
        "b74ebbe6b0d6427698c6606485147e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9b13e039f14e3396900bc7c19ed4c6",
            "placeholder": "​",
            "style": "IPY_MODEL_98fdd819eae54e199559ef067fc05697",
            "value": " 6/6 [00:00&lt;00:00, 160.60it/s]"
          }
        },
        "80aba6b93e5a44f6bc3e3bf9dba04c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b168182731d4ffb9eb353ed38f888f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4884b00481468c92200bcae2fbb366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c264d1fd17747b2bfc044dee0e7c79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d4ce004ae54ab5b47e901aac2f9b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e9b13e039f14e3396900bc7c19ed4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fdd819eae54e199559ef067fc05697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}